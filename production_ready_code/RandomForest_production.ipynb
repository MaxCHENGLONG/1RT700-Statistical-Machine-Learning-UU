{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cd98aa-4f8c-448a-9b83-566cacb512bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunandclouds/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy 0.87543\n",
      "0.81\n",
      "0.81 1.0\n",
      "0 0.0\n",
      "0.8775\n",
      "0.91 0.95\n",
      "0.72 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:10, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble accuracy 0.8458333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:20,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble accuracy 0.8958333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:29,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble accuracy 0.8791666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:39,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble accuracy 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:49,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble accuracy 0.8958333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  9.,  9., 19., 21., 69., 68., 33., 17.,  4.]),\n",
       " array([0.8525, 0.8565, 0.8605, 0.8645, 0.8685, 0.8725, 0.8765, 0.8805,\n",
       "        0.8845, 0.8885, 0.8925]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'training_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data['increase_stock_binary'] = data['increase_stock'].apply(lambda x: 1 if x == 'high_bike_demand' else 0)\n",
    "data = data.drop([\"increase_stock\"], axis=1)\n",
    "\n",
    "X = data.to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "y = X[:,-1].astype(np.float32)\n",
    "X = X[:,:-1].astype(np.float32)\n",
    "\n",
    "metric = lambda a, b: (a == b).mean()\n",
    "\n",
    "def RandomForestEnsemble(x, models):\n",
    "    predictions = [model.predict_proba(x) for model in models]\n",
    "    proba1 = np.mean(predictions, axis=0)[:, 1] # probability of predicting label 1\n",
    "    return proba1.round() # [0,0,0,1,0,1,0,0,0,...]\n",
    "\n",
    "def compute_precision(predictions, labels, positive_label=1):\n",
    "    TP = ((predictions == positive_label) & (labels == positive_label)).sum().item()\n",
    "    FP = ((predictions == positive_label) & (labels != positive_label)).sum().item()\n",
    "    return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "def compute_recall(predictions, labels, positive_label=1):\n",
    "    TP = ((predictions == positive_label) & (labels == positive_label)).sum().item()\n",
    "    FN = ((predictions != positive_label) & (labels == positive_label)).sum().item()\n",
    "    return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0, shuffle=True)\n",
    "\n",
    "seeds = range(50)\n",
    "scores = []\n",
    "models = []\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for s in seeds:\n",
    "    # Note how the indices between the validation set and train set are flipped.\n",
    "    # This means that the classifier will be trained on less than 50% of the data.\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=200, max_depth=100, criterion=\"entropy\",\n",
    "            random_state=s, n_jobs=-1\n",
    "        )\n",
    "        clf.fit(X_train[train_index], y_train[train_index])\n",
    "        # accuracy = clf.score(X_train[test_index], y_train[test_index])\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        scores.append(accuracy)\n",
    "        models.append(clf)\n",
    "\n",
    "print(\"average accuracy\", np.mean(scores))\n",
    "\n",
    "X_pred = RandomForestEnsemble(X_test, models)\n",
    "metric(X_pred, y_test)\n",
    "\n",
    "X_pred = np.zeros(len(y_test))\n",
    "print(metric(X_pred, y_test))\n",
    "for positive_label in [0, 1]:\n",
    "    recall = compute_recall(X_pred, y_test, positive_label)\n",
    "    precision = compute_precision(X_pred, y_test, positive_label)\n",
    "    print(round(precision, 2), round(recall, 2))\n",
    "\n",
    "X_pred = RandomForestEnsemble(X_test, models)\n",
    "print(metric(X_pred, y_test))\n",
    "for positive_label in [0, 1]:\n",
    "    recall = compute_recall(X_pred, y_test, positive_label)\n",
    "    precision = compute_precision(X_pred, y_test, positive_label)\n",
    "    print(round(precision, 2), round(recall, 2))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0, shuffle=True)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=100, criterion=\"entropy\", oob_score=True,\n",
    "    random_state=0, n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "seeds = range(10)\n",
    "# kf = StraKFold(5, random_state=0, shuffle=True)\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(kf.split(X_train, y_train))):\n",
    "    X_, X_test = X[train_index], X[test_index]\n",
    "    y_, y_test = y[train_index], y[test_index]\n",
    "    models = []\n",
    "    \n",
    "    # This loop creates a list of 3 * seeds classifiers using Bagging,\n",
    "    # by splitting the training set into 3 sets. \n",
    "    for s in seeds:\n",
    "        # Note how the indices between the validation set and train set are flipped.\n",
    "        # This means that the classifier will be trained on less than 50% of the data.\n",
    "        for i, (train_index_, _) in enumerate(KFold(n_splits=3).split(X_)):\n",
    "            X_train = X_[train_index_]\n",
    "            y_train = y_[train_index_]\n",
    "            clf = RandomForestClassifier(\n",
    "                n_estimators=200, max_depth=100, criterion=\"entropy\",\n",
    "                random_state=s, n_jobs=-1\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "            models.append(clf)\n",
    "\n",
    "    X_pred = RandomForestEnsemble(X_test, models)\n",
    "    print(\"ensemble accuracy\", metric(X_pred, y_test))\n",
    "\n",
    "plt.hist(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a8dea-0469-496b-bbb5-83e0bfe49850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
